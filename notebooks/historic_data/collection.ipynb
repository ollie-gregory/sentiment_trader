{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d30612a9",
   "metadata": {},
   "source": [
    "# Historical Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f8971",
   "metadata": {},
   "source": [
    "In this notebook, I am exploring how I can collect historical price, news and other data for a given stock. I will be looking at Alpha Vantage and the Reddit API to start with. I will also store the data locally in a MySQL database before migrating it to a cloud database on Digital Ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfa133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import collection_functions as c\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8a2c9",
   "metadata": {},
   "source": [
    "## Alpha Vantage API for Price Data\n",
    "\n",
    "Alpha Vantage allows 25 API calls per day for free so I will be using this sparingly for now to collect and store as much historical data as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3293420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_api_key = json.load(open('../../secrets.json'))['alpha_vantage']\n",
    "db_password = json.load(open('../../secrets.json'))['database_password']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e775f9d",
   "metadata": {},
   "source": [
    "Each request takes in a series of parameters that determine the stock, the type of data, the type of output and the granularity -- among other things. The full API documentation can be found [here](https://www.alphavantage.co/documentation/).\n",
    "\n",
    "Initially, I look at the TIME_SERIES_INTRADAY endpoint for the S&P 500 at the 1 minute level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2147dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_params = {\n",
    "    'function' : 'TIME_SERIES_INTRADAY',\n",
    "    'symbol' : 'SPY',\n",
    "    'interval' : '1min',\n",
    "    'outputsize' : 'compact',\n",
    "    'datatype' : 'json',\n",
    "    'apikey' : av_api_key,\n",
    "}\n",
    "\n",
    "url = c.get_av_request_url(request_params) # This is a function from collection_functions.py that builds the URL for the API request from the parameters.\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c009dc",
   "metadata": {},
   "source": [
    "We then perform the request which returns a JSON object with some metadata about the request and the time series data itself. The time series data is a dictionary with the time as the key and the OHLCV data as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5303ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2850c9c",
   "metadata": {},
   "source": [
    "Next up, we need to transform the data in order to insert it into the database. First, we convert it to a pandas dataframe before converting each column to the appropriate data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82800170",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['Time Series (1min)']).T # Convert the JSON to pandas, and then transpose it so that the timestamps are the index.\n",
    "\n",
    "df['interval'] = data['Meta Data']['4. Interval'] # Create a new column for the interval, which is constant for this request.\n",
    "\n",
    "df.rename(columns={'1. open' : 'open_price', '2. high' : 'high_price',\n",
    "                   '3. low' : 'low_price', '4. close' : 'close_price',\n",
    "                   '5. volume' : 'volume'}, inplace=True) # Rename the columns for the database (not strictly necessary, but makes it clearer).\n",
    "\n",
    "# Convert the numeric columns to float, as they are currently strings.\n",
    "df[['open_price', 'high_price', 'low_price', 'close_price', 'volume']] = df[['open_price', 'high_price', 'low_price', 'close_price', 'volume']].astype(float)\n",
    "\n",
    "# set the index as its own column and convert to a timestamp\n",
    "df['close_timestamp'] = pd.to_datetime(df.index)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b38a22",
   "metadata": {},
   "source": [
    "The next stage is to get the stock_id for the S&P 500 from the database so that can add it to our dataframe before inserting it into the database. We do this with a `SELECT FROM WHERE` query to get the stock_id for the 'SPY' ticker symbol. We then add a new column to the dataframe with the stock_id.\n",
    "\n",
    "In order to recreate this you will need to have a MySQL database set up locally with the schema defined in the `/database/DDL.sql` file. Adjust the database connection parameters as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = data['Meta Data']['2. Symbol'] # Get the stock symbol from the metadata.\n",
    "\n",
    "# Connect to the *LOCAL* MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    port=3306,\n",
    "    user='root',\n",
    "    password=db_password,\n",
    "    database='DRIFTBASE'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Collect the stock_id from the STOCK table using the symbol.\n",
    "cursor.execute(f\"SELECT stock_id FROM STOCK WHERE ticker='{symbol}';\")\n",
    "stock_id = cursor.fetchone()[0]\n",
    "\n",
    "df['stock_id'] = stock_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed418e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "INSERT IGNORE INTO HISTORIC_PRICE (`stock_id`, `interval`, `close_timestamp`, `open_price`, `high_price`, `low_price`, `close_price`, `volume`)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s);\n",
    "\"\"\"\n",
    "\n",
    "records = df[['stock_id', 'interval', 'close_timestamp', 'open_price', 'high_price', 'low_price', 'close_price', 'volume']].values.tolist()\n",
    "\n",
    "cursor.executemany(insert_query, records)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
